{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 チュートリアル[転移学習]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以前、CIFAR-10データセットを用いて、CNNを自力で組んで学習させるチュートリアルを書きました。最近（2018/01/18あたり）、転移学習がホットな話題になっているようなので、CIFAR-10を題材に転移学習を扱ってみたいと思います。なお、精度については一切求めていないので注意してください。より高い精度が欲しい場合、ハイパーパラメータを変更する必要があります。\n",
    "\n",
    "\n",
    "実行環境は以下のとおりです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 転移学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 転移学習とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "転移学習は英語ではTransfer Learningと言います。なにがTransferなのかは私自身よくわからないのですが、これは何か？大雑把に言えば、「すでに得られている学習結果を、他の学習に使う」手法です。たとえば、すでに大量のカテゴリー分類に対して大量の画像を学習させたデータセット(ImageNetなど)を、もっと小さいデータセットに対して使うことができます。すでに学習させてあるデータセットのネットワークは、（普通）極めて複雑なものですが、この最後の層だけに対して、小さいデータセットを学習させると、より少ないリソース、より少ない学習時間でよい精度の学習結果を得ることができます。この操作を**fine tuning**とか言ったりします。\n",
    "\n",
    "参考 [転移学習：機械学習の次のフロンティアへの招待](https://qiita.com/icoxfog417/items/48cbf087dd22f1f8c6f4)\n",
    "\n",
    "この記事では、どういうときに転移学習が使えるのかという可能性の話は脇においておいて、実際問題どういう風に転移学習を行うかに焦点を絞ってみたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "転移学習、特にfine tuningでいじるのは、ネットワークの構造だけです。というわけで、特に以下の部分に絞って議論していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = 10\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(\n",
    "            32, \n",
    "            kernel_size=(3, 3), \n",
    "            padding='same',\n",
    "            input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(\n",
    "            32, \n",
    "            kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(\n",
    "            (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(\n",
    "            64, \n",
    "            kernel_size=(3, 3), \n",
    "            padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(\n",
    "            64, \n",
    "            kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて、CIFAR-10は画像を10種類に分類するタスクです。転移学習は、**すでに学習させてあるモデルを再利用する**学習なので、どこからかそういうモデル(厳密に言えば.h5ファイル)を取ってこないといけません。また、そのモデルがどういうネットワーク構造で学習されているかも注目する必要があります。というのも、fine tuningでは最後の数層だけを学習させるので、もととなるネットワーク構造が異なれば、結果も異なるからです。\n",
    "\n",
    "Kerasの[公式ドキュメント](https://keras.io/ja/applications/)を見れば、`Xception`とか`VGG16`とかあると思います。これがネットワーク構造で、実際に私達が組むことができないくらい複雑なものです。ここでは試しにVGG16(というネットワーク構造)を使ってみます。Xceptionも可能ですが、ネットワーク構造が複雑すぎて時間がかかります。\n",
    "\n",
    "[TensorFlow : 画像分類 : ResNet, Inception-v3, Xception 比較](http://tensorflow.classcat.com/2017/05/15/tensorflow-cnn-model-comparison/)\n",
    "\n",
    "ところで、VGG16で学習させた結果を使うことはわかりましたが、なにを学習させた結果を使うべきでしょうか？これはImageNetというデータセットで、普通にGPUを使うと1ヶ月以上かかるほど大きなものです。でも安心してください、すでに学習し、保存されているものが使えます。この記事を書いている段階では`14,197,122 images, 21841 synsets indexed`らしいです。半端ないですね。このような大きなデータセットの学習結果を使って、CIFAR-10という小さいカテゴリーの分類タスクを実行してみたいと思います。それがこのチュートリアルの内容です。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "言葉だけではわかりにくいと思うので、公式ドキュメントから以下のサンプルコードを実行してみたいと思います。すでに学習させているモデルを使うので、内容としては付録Aでやったものと同じです。判別に使う画像は本論で扱った「いらすとや」の車の画像です。初めて実行する際には、大きなモデル(XceptionでImageNetを学習させたモデル)のh5ファイルをダウンロードする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02701002', 'ambulance', 0.49092665), ('n04065272', 'recreational_vehicle', 0.45504904), ('n03769881', 'minibus', 0.015279585)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "xce_model = Xception(weights='imagenet')\n",
    "\n",
    "img_path = 'images/car.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "y = image.img_to_array(img)\n",
    "y = np.expand_dims(y, axis=0)\n",
    "y = preprocess_input(y)\n",
    "\n",
    "preds = xce_model.predict(y)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、車を分類することができました。結果は明らかに間違っています。ただここでの問題は、私達が扱いたいのはたったの10種類の分類タスクなので、ambulanceかどうかは関係ありません。そこまで細かいカテゴリー分類は求めていないんですね。そのため、以降「CIFAR-10で扱う10種類のカテゴリーに正しく分類できれば良い」とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 転移学習を行う - Fine Tuning -\n",
    "\n",
    "では、実際にfine tuningを行って、CIFAR-10に対して転移学習を適用させてみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの準備までは同じなので、以下を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR-10 dataset\n",
      "50000 training samples\n",
      "10000 test samples\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlipr\n",
    "import os\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load and preprocess data\n",
    "# ---------------------------------------------------------\n",
    "data = dlipr.cifar.load_cifar10()\n",
    "\n",
    "# preprocess the data in a suitable way\n",
    "# reshape the image matrices to vectors\n",
    "#RGB 255 = white, 0 = black\n",
    "X_train = data.train_images.reshape([-1, 32, 32, 3])\n",
    "X_test = data.test_images.reshape([-1, 32, 32, 3])\n",
    "print('%i training samples' % X_train.shape[0])\n",
    "print('%i test samples' % X_test.shape[0])\n",
    "print(X_train.shape)\n",
    "\n",
    "# convert integer RGB values (0-255) to float values (0-1)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert class labels to one-hot encodings\n",
    "Y_train = to_categorical(data.train_labels, 10)\n",
    "Y_test = to_categorical(data.test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に層を重ねていきますが、Xceptionの構造を使うので、すべての層を通過した後のモデルのインスタンスを`base_model`として取り出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後で、Xceptionのネットワーク構造を固定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、`base_model`のあとで追加された層に関しては、CIFAR-10の学習で影響を受けます。すなわち、新たにウエイトが決まることになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 15,250,250\n",
      "Trainable params: 535,562\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークの構造が決まれば後は同様です。今回は`Earlystopping`を`callback`に追加しておくことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/40\n",
      " - 1395s - loss: 1.3682 - acc: 0.5227 - val_loss: 1.2142 - val_acc: 0.5686\n",
      "Epoch 2/40\n",
      " - 1593s - loss: 1.1706 - acc: 0.5902 - val_loss: 1.1308 - val_acc: 0.6032\n",
      "Epoch 3/40\n",
      " - 1717s - loss: 1.1004 - acc: 0.6152 - val_loss: 1.1175 - val_acc: 0.6118\n",
      "Epoch 4/40\n",
      " - 1714s - loss: 1.0435 - acc: 0.6345 - val_loss: 1.0917 - val_acc: 0.6164\n",
      "Epoch 5/40\n",
      " - 1715s - loss: 0.9950 - acc: 0.6526 - val_loss: 1.0746 - val_acc: 0.6180\n",
      "Epoch 6/40\n",
      " - 1611s - loss: 0.9492 - acc: 0.6672 - val_loss: 1.0611 - val_acc: 0.6260\n",
      "Epoch 7/40\n",
      " - 873s - loss: 0.9130 - acc: 0.6799 - val_loss: 1.0737 - val_acc: 0.6268\n",
      "Epoch 8/40\n",
      " - 875s - loss: 0.8717 - acc: 0.6941 - val_loss: 1.0665 - val_acc: 0.6296\n",
      "Epoch 9/40\n",
      " - 772s - loss: 0.8308 - acc: 0.7112 - val_loss: 1.0576 - val_acc: 0.6374\n",
      "Epoch 10/40\n",
      " - 930s - loss: 0.7930 - acc: 0.7241 - val_loss: 1.0613 - val_acc: 0.6318\n",
      "Epoch 11/40\n",
      " - 823s - loss: 0.7539 - acc: 0.7378 - val_loss: 1.0596 - val_acc: 0.6354\n",
      "Epoch 12/40\n",
      " - 1195s - loss: 0.7161 - acc: 0.7517 - val_loss: 1.0625 - val_acc: 0.6474\n",
      "Test score: 1.10295817041\n",
      "Test accuracy: 0.6277\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=Adam(lr=0.001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "fit = model.fit(X_train, Y_train,\n",
    "              batch_size=128,\n",
    "              epochs=40, #shouldn't be raised to 100, because the overfitting occurs.\n",
    "              verbose=2,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[es]\n",
    "                )\n",
    "\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                    verbose=0\n",
    "                    )\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Some plots\n",
    "# ----------------------------------------------\n",
    "\n",
    "# make output directory\n",
    "folder = 'results'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "model.save(os.path.join(folder, 'my_model-tl.h5'))\n",
    "\n",
    "# predicted probabilities for the test set\n",
    "Yp = model.predict(X_test)\n",
    "yp = np.argmax(Yp, axis=1)\n",
    "\n",
    "# plot some test images along with the prediction\n",
    "for i in range(10):\n",
    "    dlipr.utils.plot_prediction(\n",
    "        Yp[i],\n",
    "        data.test_images[i],\n",
    "        data.test_labels[i],\n",
    "        data.classes,\n",
    "        fname=os.path.join(folder, 'test-%i.png' % i))\n",
    "\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"loss for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"loss for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit)\n",
    "plot_history_acc(fit)\n",
    "fig.savefig(os.path.join(folder, 'cifar10-tutorial-tl.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='results/cifar10-tutorial-tl.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "となり、精度62.77%が得られました。結果は本論で組んだネットワークのものより悪くなりましたが、これはネットワーク構造やハイパーパラメータのためです。ネットワークの構造が変わっているので、fine tuningの段階でハイパーパラメータを調整しないとよい精度は得られません。\n",
    "\n",
    "転移学習については以上のような段階を踏みます。VGG16内部のネットワーク構造の最後の数枚の層をfreezeさせたりすることもできますが、それはサンプルコード等から試されることをおすすめします(~~リソースが足りない~~)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
